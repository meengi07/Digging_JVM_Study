# 3.1 들어가며
GC의 역사는 1960년 MIT에서 개발된 리스프라는 언어이며, 자바의 역사보다 훨씬 오래됐다.
리스프의 창시자인 존 맥카시가 말한 'GC가 처리해야 할 문제' 세 가지
- 어떤 메모리를 회수해야 하나?
- 언제 회수해야 하나?
- 어떻게 회수해야 하나?
  다시 말해, GC의 주된 역할은 적절한 시기에 적절한 방법으로 적절한 메모리 영역의 데이터를 회수해야 하는 것이다.
  또한 객체의 생명 주기는 런타임에만 알 수 있기에 메모리 회수와 할당은 동적으로 수행해야 한다.

# 3.2 대상이 죽었는가?
자바에서 거의 모든 객체 인스턴스는 힙에 저장된다.
GC가 힙을 청소하려면 객체의 생사 여부를 판단해야 한다.
이번 절에선 객체의 생사 판단 기준에 대해 알아보자.

## 3.2.1 참조 카운팅 알고리즘
객체의 생서 여부를 판단하는 가장 기초적이고 단순한 알고리즘이다.
- 객체를 가리키는 참조 카운터를 추가
- 참조하는 곳이 하나 늘어날 때마다 카운터 값++
- 참조하는 곳이 하나 줄어들 때마다 카운터 값--
- 카운터 값이 0인 인스턴스는 더 사용될 수 없음

하지만 여러 예외 케이스를 고려할 때, 실제 JVM에서 해당 알고리즘을 사용하는 것은 불가능하다.
대표적으로 순환 참조 문제가 존재한다.
```java
/**  
 * VM Option : -Xlog:gc* 
*/
public class ReferenceCouningGC {  
    public Object instance = null;  
    private static final int _1MB = 1024 * 1024;  
    private byte[] bigSize = new byte[2 * _1MB];  
  
    public static void testGC() {  
        ReferenceCouningGC objA = new ReferenceCouningGC();  
        ReferenceCouningGC objB = new ReferenceCouningGC();  
  
        objA.instance = objB;  
        objB.instance = objA;  
  
        objA = null;  
        objB = null;  
  
        System.gc();  
    }  
  
    public static void main(String[] args) {  
        testGC();  
    }  
}
```
![[JVM 3장 - 순환 참조 객체 회수 로그.png]]
-> 위 코드 실행을 통해 JVM은 참조 카운팅 알고리즘을 사용하지 않음을 알 수 있음

## 3.2.2 도달 가능성 분석 알고리즘
참조 카운팅 알고리즘의 한계는 명확하기에 현재 주류 프로그래밍 언어는 모두 객체 생사 판단에 도달 가능성 분석 알고리즘을 활용한다.

이 알고리즘의 핵심은 GC루트라고 하는 루트 객체를 시작 노드 집합으로 삼아 참조 객체들을 탐색해 나가는 것이다. 이 과정에서 만들어진 경로를 참조 체인이라고 한다.
이 때, **특정 객체에 대한 참조 체인이 존재하지 않는다면 해당 객체는 회수 대상**이 된다.
![[JVM 3장 - 도달 가능성 분석 알고리즘의 객체 생사 판별.png]]

### GC루트로 사용될 수 있는 객체 목록
- VM 스택에서 참조하는 객체(매개 변수, 지역 변수 등 지역 변수 테이블)
- 메서드 영역에서 클래스가 정적 필드로 참조하는 객체
- 메서드 영역에서 상수로 참조되는 객체(문자열 테이블 안의 참조 -> String 상수 풀)
- 네이티브 메서드 스택에서 JNI가 참조하는 객체
- JVM 내부에서 쓰이는 참조(기본 데이터 타입에 해당하는 Class 객체, 일부 상주 예외 객체)
- 동기화 락으로 잠겨있는 모든 객체
- JVM 내부 상황을 반영하는 JMXBean
- 그 외 GC 종류나 현재 회수 중인 메모리 영역에 따라 다른 객체들도 임시 추가 될 수 있음
  GC루트로부터 참조를 탐색하는 과정에서 주의할 점은 한 객체가 다른 영역에 존재하는 객체를 참조할 수도 있다는 점이다. 그러므로 연관된 영역의 객체들도 GC루트 집합에 포함해야 알고리즘을 정확하게 구현할 수 있다.

## 3.2.3 참조의 개념
전통적인 참조의 개념은 다음과 같다.
- 참조 타입 데이터에 저장된 값이 다른 메모리 조각의 시작 주소를 뜻한다면, 이 참조 데이터를 해당 메모리 조각이나 객체를 참조한다고 말한다.

현 시점에서 해당 개념은 범위가 좁다.
그래서 현재는 참조 개념을 확장해 아래와 같이 네 가지로 구분한다.
- **강한 참조**
  - 가장 전통적인 참조
  - 프로그램 코드에서 참조를 할당하는 것이며 **GC 회수 대상이 아님**
- **부드러운 참조**
  - 유용하지만 필수는 아닌 객체를 표현
  - 메모리 오버플로 발생 직전에 두 번째 회수를 위한 회수 목록에 추가됨
  - **두 번째 회수 이후에도 메모리가 부족한 경우 회수 대상이 됨**
- **약한 참조**
  - 부드러운 참조와 비슷하지만 연결 강도가 더 약함
  - **다음 가비지 컬렉션까지만 생존**
- **유령 참조**
  - 객체 수명에 영향을 주지 않으며, 유령 참조를 통해 객체 인스턴스를 가져오는 것은 불가능

>[!NOTE]
> **finalize()**
> 도달 불가능한 객체라고 해서 반드시 회수 되어야 하는 것은 아니다.
> 확실한 회수 대상이 되려면 두 번의 표시 과정을 거쳐야 하는데 이 때 활용되는 것이 finalize()다.
> 실행 비용도 높고 불확실성도 크기에 절대 사용 하지마라

## 3.2.4 메서드 영역 회수
메서드 영역은 GC의 회수 대상이 아니다는 거짓이다.
다만, 메서드 영역의 회수는 조건이 까다롭고 비용 효율이 좋지 않다. .

메서드 영역에서 GC의 회수 대상은 크게 상수, 클래스 두 가지다.
상수의 경우 'java'라는 리터럴을 참조하는 문자열 객체가 전혀 없다면 해당 상수는 회수 대상이 된다.
클래스의 경우 다음 세 가지 조건을 만족해야 한다.
- 힙 영역에 해당 클래스와 하위 클래스의 인스턴스가 존재하지 않음
- 해당 클래스를 읽어들인 클래스 로더가 회수 되어야 함
- 해당 클래스의 java.lang.Class 객체를 참조하는 객체가 없고, 리플렉션으로도 해당 기능을 이용하지 않아야 함
  **-> 회수를 허용한다지 반드시 회수하는 것은 아님**

# 3.3 가비지 컬렉션 알고리즘
이번 절에서 소개하는 알고리즘은 모두 추적 GC(도달 가능성 분석)에 속한다.
## 3.3.1 세대 단위 컬렉션 이론
세대 단위 컬렉션 이론은 다음과 같은 가설에서 시작하며, 현재 사용 VM 대부분이 해당 이론에 기초해 설계 됐다.
- **약한 세대 가설** - 대다수 객체는 일찍 죽는다.
- **강한 세대 가설** - GC 회수 과정에서 살아남은 횟수가 늘어날수록 더 오래 살 가능성이 커진다.
  이 가설에 따라 **자바 힙을 몇 개의 영역으로 구분하고, 객체들의 나이에 따라 각기 다른 영역에 할당하는 것**이 세대 단위 컬렉션 이론의 핵심이다.

힙 영역을 몇 가지로 구분하면 GC는 한 번에 하나 또는 몇 개 영역만 선택해 회수할 수 있는데 이를 기준으로 마이너 GC(신세대), 메이저 GC(구세대), 전체 GC로 구분할 수 있다.
각 영역의 객체 생존 특성에 따라 마크-스윕, 마크-카피, 마크-컴패트 알고리즘을 구분해 회수하게 된다.

이 이론에 기초하여 VM 설계자들은 보통 자바 힙을 두 개 영역으로 구분한다.
- **신세대**
- **구세대**
  GC 회수 과정에서 살아 남은 신세대 영역의 객체들은 구세대 영역으로 승격된다.

### 그렇다면 이 두 가지 이론으로 완벽한 설계가 가능할까?
객체들은 단독으로 존재하지 않고 다른 세대에 존재하는 객체들을 참조하는 상황이 존재하기 때문에 두 가설만 가지고 완벽한 설계를 하는 것은 불가능 하다.
예를 들어, 신세대에서만 가비지 컬렉션을 수행하고 싶어도 구세대에서 신세대의 객체를 참조 중인 경우가 존재한다. 반대의 경우도 마찬가지인데, 이 경우 구세대 전체를 탐색하는 것은 성능 면에서 부담이 크다.
그러므로 **도달 가능성을 분석할 때, 고정된 GC 루트뿐만 아니라 구세대 객체까지 모두 탐색해야 결과를 신뢰**할 수 있다.

### 약점을 어떻게 보완할까?
앞선 두 가설의 예외 케이스를 보완하기 위해 아래 가설이 추가적으로 필요하다.
- **세대 간 참조 가설** - 세대 간 참조의 개수는 같은 세대 안에서의 참조보다 훨씬 적다.
  **즉, 상호 참조 관계의 두 객체는 생명 주기가 비슷한 경향이 있다.**
  이 가설에 따르면 세대 간 참조의 수는 적기에 구세대 전체를 탐색하는 것은 낭비다.

이를 해결하기 위해 신세대에 **기억 집합**이라는 전역 데이터 구조를 둔다.
이 구조는 **구세대를 작은 조각 몇 개로 나누고, 그중 어느 조각에 세대 간 참조가 있는지 기록해 관리하기 위함**이다.
마이너 GC가 수행되면 세대 간 참조를 포함하는 작은 메모리 블록 안의 객체들만 GC 루트에 추가된다.

## 3.3.2 마크-스윕 알고리즘
해당 알고리즘은 가장 기본적인 가비지 컬렉션 알고리즘이다.
![[JVM 3장 - 마크-스윕 알고리즘.png]]
방식은 아래와 같다.
- 회수할 객체를 표시
- 표시된 객체를 회수
  단순한만큼 큰 단점이 두 가지 존재한다.
- **실행 효율이 일정하지 않음**
  - 객체가 많아질수록 효율이 떨어짐
- **메모리 파편화가 심함**
  - GC가 회수하고 간 자리에 불연속적인 메모리 파편이 만들어짐
  - 파편화가 심해지면 큰 객체를 만들 수 없고, 이에 추가적인 가비지 컬렉션이 발생

## 3.3.3 마크-카피 알고리즘
앞선 마크-스윕 알고리즘의 단점을 해결하기 위해 나온 알고리즘이다 .
해당 알고리즘은 **가용 메모리 영역을 이등분하여 한 번에 한 블록만 사용**한다.
![[JVM 3장 - 마크-카피 알고리즘.png]]
위 그림에서 볼 수 있듯이 메모리 파편화 문제를 해결할 수 있다. 하지만 여전히 아래와 같은 문제가 존재한다.
- 회수 대상이 적은 경우 여전히 비용 효율이 나쁨(대다수가 회수된다면 ㄱㅊ)
- 이등분하여 한 영역만 사용하기 때문에 메모리 공간을 낭비
### 그럼에도 불구하고 오늘날 대부분의 상용 VM은 해당 방식을 채택
IBM의 연구 결과 신세대 객체 중 98%가 첫 번째 가비지 컬렉션에서 회수된다는 것을 알게 됐다.
그러므로 가용 메모리 영역을 반드시 이등분할 필요가 없게 된다.
이 이론을 구체화하면 아래와 같다.
- 신세대를 하나의 큰 에덴 공간과 두 개의 작은 생존자 공간으로 나눔
- 이 공간의 비율은 8(에덴) : 1(생존자)이다.
- 메모리 할당시 생존자 공간 하나와 에덴만 사용
- 가비지 컬렉션이 시작되면 에덴과 생존자 공간에서 살아남은 객체들을 나머지 생존자 공간으로 복사 후 에덴과 이전 생존자 공간을 지운다.
  이를 통해 메모리 낭비 공간을 10%로 줄일 수 있다.

### 만약 10%(생존자 공간 크기)가 넘는 크기의 객체들이 살아 남는다면?
98%의 객체가 회수된다는 연구 결과는 일반적인 상황을 가정한 결과다.
이를 해결하기 위해 **메모리 할당 보증**이란 메커니즘이 추가된다.
마이너 GC에서 생존한 객체를 생존자 공간에 모두 할당하지 못한다면, 다른 메모리 영역(대부분 구세대)을 활용해 메모리 할당을 보증하는 것이 핵심이다.

## 3.3.4 마크-컴팩트 알고리즘
마크-카피 알고리즘에서 해결하지 못한 문제 하나가 여전히 남아 있다.
- **객체 생존율이 높을수록 효율이 떨어진다.**
  때문에 마크-카피 알고리즘은 구세대에는 적합하지 않다.

![[JVM 3장 - 마크-컴팩트 알고리즘.png]]
표시 단계는 마크-스윕과 같지만 핵심적인 차이는 메모리 이동에 있다. 컴팩트 단계에서 회수 대상을 바로 회수하지 않고, 생존할 객체들을 메모리 영역의 한쪽 끝으로 모은 다음 나머지 공간을 한꺼번에 비운다. 객체를 이동하여 재할당하기 때문에 이동된 객체들을 가리키던 기존 참조들을 모두 갱신해야 한다. 이를 통해 메모리 파편화의 문제를 해결할 수 있다.

### 그렇다면 마크-컴팩트 알고리즘으로 충분한가?
구세대처럼 생존 객체가 많다면 이동된 객체들의 기존 참조를 모두 갱신하는 것은 효율이 떨어지는 일이다.
이보다 더 큰 문제는 **객체 이동을 할 땐, 사용자 애플리케이션을 모두 멈춘 상태에서 진행**해야 한다. 이를 'stop the world'라 부른다.

결국 객체 이동 여부에 따라 아래와 같은 트레이드 오프를 고려해야 한다.
- **객체 이동 o**
  - 스톱더 월드를 최소화거나 없애기 위한 **복잡한 회수 작업**
  - 시스템 전체 처리량 기준에서 유리한 방식
  - 여기서 처리량은 사용자 프로그램과 GC의 효율을 포괄하는 개념
- **객체 이동 x**
  - 메모리 파편화로 해결을 위한 **복잡한 할당 작업**
  - 일시 정지 시간 기준에서 유리한 방식
    그러므로 마크-스윕과 마크-컴팩트를 혼용하여 단점을 최대한 상쇄시키는 GC도 존재한다.
    -> CMS

# 3.4 핫스팟 알고리즘 상세 구현
## 3.4.1 루트 노드 열거(Root Node Enumeration)
루트 노드 열거란 **도달 가능성 분석 알고리즘에서 GC 루트 집합으로부터 참조 체인을 찾는 작업**을 말한다.

루트 노드 열거는 반드시 일관성이 보장된 스냅숏 상태에서 수행되어야 하므로 스톱 더 월드 문제를 피할 수 없다. 즉, **해당 작업 중에 참조 관계가 변하면 신뢰성이 깨지게 된다.**
이는 모든 GC들이 가지고 있는 문제다.

현재 주류 VM들은 정확한 메모리 관리 기술에 기반한 '정확한 가비지 컬렉션'을 사용한다.
따라서 사용자 스레드가 정지한 후 실행 컨텍스트와 전역 참조의 위치를 빠짐없이 확인할 필요가 없다. 대신 **가상 머신이 객체 참조가 저장된 위치를 직접 알아낼 방법**이 있어야 한다.

핫스팟은 OopMap이라는 데이터 구조를 사용해 이 문제를 해결한다.
- 클래스 로딩이 완료되면 객체에 포함된 각 데이터의 타입을 확인
- JIT 컴파일 과정에서 스택의 어느 위치와 어느 레지스터의 데이터가 참조인지 기록
- 이를 통해 컬렉터는 **GC 루트로부터 시작해 추적 없이 스캔 과정에서 정보를 획득**

정리하자면, 아래와 같다.
- 루트 노드 열거에서 모든 참조를 하나씩 탐색하는 것은 효율이 떨어진다.
  - 작업 중 일관성 보장을 위해 스톱 더 월드 문제가 발생하는데 그 양이 많다면 그만큼 지연 시간이 늘어나기 때문이다.
- 이를 해결하기 위해 현대의 JVM은 '정확한 가비지 컬렉션'을 사용
  - 해당 방식은 '정확한 메모리 관리'에 기반한다.
  - 이를 구현하기 위해 내부적으로 OopMap이란 자료 구조를 사용(핫스팟의 경우)
  - 해당 자료 구조는 JIT 컴파일 단계에서 스캐닝 하는 과정에 초기화 됨
- '정확한 가비지 컬렉션'을 사용하면 실행 컨텍스트와 전역 참조의 위치를 일일이 확인할 필요가 없음
>[!NOTE]
>**정확한 메모리 관리**
>정확한 메모리 관리란 VM이 메모리의 특정 위치에 있는 데이터의 구체적인 자료형을 알 수 있다는 뜻이다.

## 3.4.2 안전 지점
OopMap을 활용하면 루트 노드 열거 작업을 빠르게 완료할 수 있다.
하지만 참조 관계나 OopMap의 내용을 변경할 수 있는 명령어가 많으며, 이런 **명령어 모두에 OopMap을 만들어 넣으면 메모리를 더 많이 사용**해야 한다. 그래서 핫스팟은 모든 명령어에 OopMap을 생성하지 않는다. 대신 **안전 지점이라고 하는 특정 위치에만 기록**한다.

안전 지점의 위치를 선택하는 기준은 기본적으로 프로그램이 장시간 실행될 가능성이 있는가이다. 여기서 장시간 실행될 가능성은 명령어 흐름이 다중화되는 것을 의미한다.
-> 메서드 호출, 순환문, 예외 처리 등

### 스레드를 안전 지점에 멈추게 하는 방법은?
JNI 호출을 실행 중인 스레드를 제외한 모든 스레드를 가장 가까운 안전 지점에 멈추게하는 방법은 다음 두 가지가 있다.
- **선제적 멈춤**
  - 스레드의 코드는 GC를 신경 쓸 필요가 없음
  - 가비지 컬렉션이 실행되면 시스템이 모든 사용자 스레드를 인터럽트하는 방식
  - 만약 사용자 스레드가 멈춘 지점이 안전 지점이 아니면 재개 -> 인터럽트 반복
  - 해당 방식은 거의 사용 X
- **자발적 멈춤**
  - GC가 스레드 수행에 직접 관여 X
  - 대신 플래그 비트를 설정하고, 각 스레드가 플래그를 적극적으로 폴링하는 방식
  - 플래그 값이 true면 가장 가까운 안전 지점에 스레드가 스스로 멈춤

여기서 폴링은 적극적으로, 즉 자주 일어나므로 효율적으로 작동해야 한다.
핫스팟은 메모리 보호 트랩(memory protection trap)이라는 방법을 써서 폴링을 어셈블리 명령어 하나만으로 수행할 수 있게 단순화했다.
![[JVM 3장 - 폴링 명령어.png]]
사용자 스레드를 일시 정지해야하는 경우 가상 머신은 0x160100 메모리 페이지를 읽을 수 없게 설정한다. 이후 스레드가 test 명령어를 실행할 때 트랩에 걸렸단 예외 시그널을 던지고, 사전 등록된 예외 핸들러에서 스레드를 일시 정지시킨다.
## 3.4.3 안전 지역
안전 지점 메커니즘을 통해 짦은 시간에 GC의 프로세스가 작업을 완료할 수 있게 도와준다. 하지만 **프로세서를 할당 받지 못한 상태(sleep or block 등의 대기 상태)라면 스레드들은 VM의 인터럽트 요청에 응답할 수 없고**, 때문에 안전 지점까지 작업 수행 후 인터럽트 되어 스스로 멈출 수 없다. 또한 다시 프로세서를 할당받을 때까지 VM이 무한정 대기하는 것도 말이 안된다.

이 문제를 해결하기 위해 안전 지역의 개념이 나오게 됐다. 안전 지점을 확장한 개념(Point -> region)으로 일정 코드 영역에서는 참조 관계가 변하지 않음을 보장한다.

**사용자 스레드는** 안전 지역의 코드를 실행하기 앞서 **안전 지역에 진입했음을 표시**하고, GC는 표시가 된 스레드들은 신경 쓸 필요가 없다. **안전 지역에서 벗어나려는 스레드는 VM이 루트 노드 열거를 완료**했는지 또는 사용자 스레드를 일시 정지 시켜야 하는 **다른 가비지 컬렉션 단계를 완료했는지 확인**한다. 만약 완료되지 않았다면 해당 스레드는 안전 지역에 머무르게 된다.

## 3.4.4 기억 집합과 카드 테이블
GC는 신세대에 기억 집합이라는 자료 구조를 활용해 객체들의 세대 간 참조 문제를 해결한다.

기억 집합은 비회수 영역에서 회수 영역을 가리키는 포인터들을 기록하는 추상 데이터 구조다. (ex - 구세대 -> 신세대) 효율과 비용을 고려하지 않는다면 비회수 영역에 있는 세대 간 참조들을 Object 배열에 담아 간단히 구현할 수 있다. 하지만 **GC는 회수 작업 시 비회수 영역에서 회수 영역을 가리키는 포인터의 존재 여부만 확인**하면 된다. 즉, 배열에 세대가 참조 내용을 모두 담는 것은 비효율적인 방법이다.

그래서 기억 집합 설계자는 정밀도를 낮춰서, 즉 기록 단위를 더 크게 잡아서 공간과 관리 비용을 낮추도록 노력했다. 정밀도의 기준은 다음 세 가지로 볼 수 있다.
- **워드 정밀도**(높은 정밀함)
  - 레코드 하나가 메모리의 워드 하나에 매핑
  - 특정 레코드가 마킹되어 있다면 해당 워드가 세대 간 포인터라는 뜻
- **객체 정밀도**(중간 정밀함)
  - 레코드 하나가 객체 하나에 매핑
  - 특정 레코드가 마킹되어 있다면, 해당 객체에 다른 세대를 참조하는 필드가 존재
- **카드 정밀도**(낮은 정밀함)
  - 레코드 하나(카드)가 메모리 블록 하나에 매핑
  - 특정 레코드가 마킹되어 있다면, 해당 블록에 세대 간 참조를 지닌 객체가 존재
    이 중 카드 정밀도로 구현된 기억 집합을 카드 테이블이라고 하며, 현재 가장 널리 쓰이는 방식이다.(기억 집합은 추상 데이터 구조)
    -> 여기서 말하는 레코드는 카드 테이블의 row를 의미

카드 테이블을 구현하는 가장 간단한 형태는 바이트 배열이다. 다음 코드는 핫스팟의 기본 카드 테이블 표시 로직이다.
```java
CARD_TABLE[this address >> 9] = 1;
```
CARD_TABLE 원소 각각은 메모리 영역에서 특정 크기의 메모리 블록 하나에 대응하고, 이 메모리 블록을 카드 페이지라고 한다. 일반적으로 카드 페이지의 크기는 2의 N제곱 바이트로 정한다.
![[JVM 3장 - 카드 테이블과 카드 페이지.png]]
카드 페이지 하나의 메모리에는 보통 하나 이상의 객체가 들어 있다. 이 객체들 중에 하나라도 세대 간 포인터를 갖는 필드가 있다면, 카드 테이블에서의 해당 원소(카드)를 1로 표시하고 그 원소를 '더렵혀졌다(dirty)'고 말한다.
이를 통해 객체를 회수할 때는 카드 테이블에서 더럽혀진 원소만 확인하면 어떤 카드 페이지의 메모리 블록이 세대 간 포인터를 포함하는지 쉽게 확인할 수 있다.

>[!NOTE]
>**OopMaps와 기억 집합**
>OopMaps는 **GC 루트의 스캔 속도를 빠르게 하기 위함**. 즉, 루트 노드 열거를 빠르게 수행하기 위함
>기억 집합은 **GC 루트의 스캔 범위를 줄이기 위함**

## 3.4.5 쓰기 장벽
카드 테이블의 원소가 더럽혀지는 시점은 다른 세대의 객체가 현재 블록 안의 객체를 참조하는 시점으로 명확하다. 즉, **더럽혀지는 시점은 참조 타입 필드에 값이 대입되는 순간**이다.

문제는 객체가 대입되는 순간 해당 카드 테이블을 갱신하는 방법이다. 바이트코드를 해석해 실행하는 경우라면 상대적으로 쉽지만 **컴파일하여 실행하는 경우엔 기계어 코드 수준의 방법이 동원되어야 한다.** 이를 해결하기 위해 '쓰기 장벽'이란 기술이 사용된다.

### 읽기 장벽 VS 쓰기 장벽
- **읽기 장벽**
  - 동시 비순차 실행 문제를 해결하기 위한 메모리 장벽 기술
  - 컴파일 최적화, CPU 실행 최적화가 일어나면 명령어 실행 순서가 바뀔 수 있는데 이를 동시 비순차 실행이라 함
- **쓰기 장벽**
  - VM 수준에서 '참조 타입 필드 대입'시 사용되는 AOP라고 비유할 수 있음
  - 대입 전 쓰기 장벽을 사전 쓰기 장벽, 대입 후 쓰기 장벽을 사후 쓰기 장벽이라고 부름
  - G1 컬렉터 등장 이전엔 모두 사후 쓰기 장벽을 이용
### 쓰기 장벽엔 문제가 없는가?
쓰기 장벽으로 카드 테이블 갱신 연산을 추가하면 물론 오버헤드가 더해진다. 하지만 마이너 GC 때 구세대 전체를 스캔하는 비용보단 훨씬 저렴하다.
하지만 이 뿐만 아니라 멀티 스레드 환경에선 거짓 공유 문제를 일으킬 수 있다. 해당 문제는 쓰기 장벽을 조건부로 사용해 해결할 수 있다.
```java
if (CARD_TABLE [this address >> 9]! = 1)
	CARD_TABLE [this address >> 9] = 1;
```
JDK 7부터 핫스팟은 -XX:+UseCondCardMark 매개 변수를 추가해 거짓 공유 문제를 피했다. 물론 이 경우에도 조건을 판단해야 하기에 오버헤드가 더해진다.

>[!NOTE]
>**CPU 캐시 라인**
>CPU 캐시는 데이터를 캐시 라인 단위(일반적으로 64바이트)로 관리한다. CPU는 해당 단위로 데이터를 가져와 메모리 접근 횟수를 줄인다.

>[!NOTE]
>**거짓 공유 문제**
>현대적인 CPU의 캐시 시스템은 데이터를 캐시 라인 단위로 관리한다. 그래서 여러 스레드가 서로 다른 변수를 수정할 때, 만약 그 변수가 같은 캐시 라인에 존재한다면, write back, 무효화, 동기화 작업 등 서로 영향을 끼쳐 성능을 떨굼. 다시 말해 다른 변수를 수정함에도 같은 캐시 라인에 존재하기 때문에 실제로 공유하지 않음에도 공유하는 것처럼 보여 거짓 공유 문제라고 한다.

## 3.4.6 동시 접근 가능성 분석
루트 노드 열거 작업이 끝나면 GC는 GC 루트로부터 **객체 그래프를 탐색할 수 있고, 이 단계의 일시 정지 시간은 자바 힙 크기에 비례**한다. 참조 관계를 추적하는 가비지 컬렉션 알고리즘들에는 공통적으로 '표시(마크)' 단계가 등장하고, 이 단계에서 일시 정지 시간은 힙 크기에 비례하므로 성능에 지대한 영향을 끼친다. 반대로 이 단계에서 지연 시간을 최대한 줄일 수 있다면 거의 모든 GC에 성능 향상을 가져다 줄 수 있다.

### 왜 일시 정지된 상태에서 객체 그래프를 탐색해야 할까?
삼색 표시 기법으로 그 이유를 명확히 알 수 있다.
- **흰색**
  - GC가 방문한 적이 없는 개체
  - 그러므로 도달 가능성 분석을 시작하면 모든 객체가 흰색
  - 분석 후에도 흰색이라면 도달 불가능한 객체
- **검은색**
  - GC가 방문한 적이 있으며, 해당 객체를 가리키는 모든 참조를 스캔 완료
  - 흰색 객체를 곧바로 가리키는 것은 불가능, 회색 객체를 거쳐 가리킬 수는 있음
- **회색**
  - GC가 방문한 적이 있으나, 해당 객체를 가리키는 모든 참조를 스캔하진 않음
    만약 사용자 스레드와 컬렉터가 동시에 실행된다면 아래와 같은 두 가지 문제가 발생할 수 있다.
- **죽은 객체를 살았다고 잘못 표시**
- **살아 있는 객체를 죽었다고 잘못 표시**
  이 중 두 번째는 매우 심각한 오류이다. 이 문제는 다음 두 가지 조건이 동시 만족할 때 발생하게 된다.
- 사용자 스레드가 흰색 객체로의 새로운 참조를 검은색 객체에 추가
- 사용자 스레드가 회색 객체에서 흰색 객체로의 직간접적인 참조를 삭제

두 조건이 동시 만족할 때만 문제가 발생하기 때문에 두 조건 중 하나만 깨뜨려도 문제를 해결할 수 있다.
- **증분 업데이트**
  - 검은색 객체에 흰색 객체로의 참조가 추가되면 새로 추가된 참조를 따로 기록
  - 동시 스캔이 끝난 후 기록해 둔 검은색 객체들을 루트로 하여 재스캔
  - 검은색 객체에 흰색 객체로의 참조가 추가되면 검은색이 다시 회색으로 바뀐다
- **시작 단계 스냅숏**
  - 회색 객체가 흰색 객체로의 참조 관계를 끊으려 하면 해당 내용을 기록
  - 동시 스캔이 끝난 후 기록해둔 회색 객체들을 루트로 하여 재스캔
  - 참조 관계 삭제 여부와 상관 없이 스캔을 막 시작한 순간의 객체 그래프 스냅숏을 기준으로 스캔
    위 두 가지 해결책 또한 쓰기 장벽을 이용해 구현한다.

# 3.5 클래식 가비지 컬렉터
![[JVM 3장 - 클래식 가비지 컬렉터.png]]
## 3.5.1 시리얼 컬렉터
![[JVM 3장 - 시리얼 컬렉터.png]]
가장 기초적이고 오래된 컬렉터다. 단일 스레드로 동작하는데, 가비지 컬렉션을 단순히 하나의 GC 스레드가 모두 처리한다는 의미만 존재하는 것은 아니다. 다시 말해 **가비지 컬렉션이 시작되면 회수가 완료될 때까지 다른 모든 작업 스레드가 정지해야 한다는 것**이다.

문제가 커보이지만 실제론 최신 JDK에서도 꾸준히 지원되고 있다. 그 이유는 다른 GC들의 단일 스레드 알고리즘보다 간단하고 효율적이기 때문이다. -XX:+UseSerialGC 매개 변수를 추가해 사용할 수 있다.

신세대에선 마크-카피 알고리즘을 사용, 구세대에선 마크-컴팩트 알고리즘을 사용하여 모든 사용자 스레드를 일시 정지시킨다.
## 3.5.2 파뉴 컬렉터
파뉴 컬렉터는 멀티 스레드를 활용해 시리얼 컬렉터를 병렬화한 버전이다. 그 외엔 모든 것이 시리얼 컬렉터와 완전히 같다.

## 3.5.3 패러랠 스캐빈지 컬렉터
다른 GC들과 달리 PS 컬렉터는 처리량을 제어하는 것이 주 목표다.
여기서 처리량은 [사용자 코드 실행시간 / (사용자 코드 실행 시간 + GC 실행시간)]이다.

처리량을 정밀하게 제어할 수 있도록 매개 변수 두 가지를 제공한다.
- **-XX:MaxGCPauseMillis**(가비지 컬렉션 정지 시간 최댓값)
  - 해당 값을 작게 설정하면 가비지 컬렉션이 무조건 빨라지는 것은 아니다.
  - 반대급부로 처리량이 낮아지며, 신세대의 크기가 더 작게 할당되는 문제가 발생하기 때문
- **-XX:GCTimeRatio**(처리량 직접 지정)

이 두 변수말고도 아래와 같은 변수도 존재한다. 그리고 이러한 적응형 조율 전략이 PS컬렉터를 다른 GC들과 차별화하는 특징이다.
- **-XX:+UseAdaptiveSizePolicy**
  - 세부 설정용 매개 변수들을 일일이 지정하지 않아도 VM이 성능 모니터링 정보를 수집해 모든 매개 변수의 값을 동적으로 조율해줌

## 3.5.4 시리얼 올드 컬렉터
시리얼 컬렉터의 구세대용 버전이다. 해당 컬렉터를 사용하는 목적은 다음 두 가지의 경우다.
- JDK 5와 그 이전의 PS컬렉터와 함께 사용하기 위함
- CMS 컬렉터가 실패할 때를 위한 대비책(동시 회수 중 동시 모드 실패)

## 3.5.5 패러렐 올드 컬렉터
PS 컬렉터의 구세대용 버전이다.

## 3.5.6 CMS 컬렉터(Concurrent Mark and Sweep)
CMS 컬렉터의 핵심은 표시, 쓸기 단계를 사용자 스레드와 동시 수행하는 것이다.
일시 정지 시간을 최소로 줄이는 것이 주 목적이기에 인터넷 서비스와 같은 애플리케이션에 적합한 컬렉터다.

마크-스윕 알고리즘을 기초로 구현됐지만 동작 방식은 다른 컬렉터들보다 복잡하다.
- **최초 표시**
  - GC와 직접 연결된 객체만 표시하므로 빠르게 끝남
- **동시 표시**
  - GC 루트와 연결된 객체 그래프 전체를 탐색
  - 시간이 오래걸리지만 사용자 스레드 정지가 없음
- **재표시**
  - 증분 업데이트를 통해 동시 표시 단계에서 참조 관계가 변경된 객체를 바로 잡음
  - 일시 정지 시간은 최초 표시보다 살짝 길다.
- **동시 쓸기**
  - 앞의 세 가지 표시 단계에서 죽었다고 판단한 객체를 회수
  - 살아있는 객체를 옮기지 않기에 사용자 스레드를 멈추지 않음

여기서 핵심은 가장 시간이 오래 걸리는 동시 표시와 동시 쓸기 단계에서 사용자 스레드를 멈추지 않는다는 것이다.

### 그럼 CMS는 완벽한가?
CMS에겐 세 가지의 큰 단점이 존재한다.
- **CMS는 프로세서 자원에 매우 민감하다.**
  - 동시 수행 단계에서 사용자 스레드를 멈추지 않더라도 애플리케이션을 느리게 하고 전체 처리량을 떨어뜨리는 것은 피할 수 없다.
  - GC 스레드도 결국엔 CPU의 연산 능력을 나눠 쓰는 스레드이기 때문이다.
- **CMS가 부유 쓰레기를 처리하지 못해 동시 모드 실패를 유발할 가능성이 있다.**
  - 동시 모드를 실패하면 전체 GC가 시작되기 때문이 오히려 성능이 떨어질 수 있는 것이 문제다.
  - 가비지 컬렉션 동안 사용자 스레드의 작업을 유지하기 위해 충분한 메모리 공간이 필요하다.
  - 결국 이러한 부유 쓰레기들은 충분한 메모리 공간 확보를 못하도록 방해하고, 이 때문에 결국 전체 GC와 같은 긴 스톱 더 월드가 수행된다.
- **CMS는 마크-스윕을 기초로하기에 메모리 파편화 문제가 발생한다.**
  - 이 경우에도 객체를 할당하기 위한 '연속된 메모리 공간'을 찾지 못하면 전체 GC가 수행된다.
  - 이를 해결하기 위해  아래와 같은 변수들을 제공한다.(136p)
  - -XX:+UserCMSCompactAtFullCollection,
  - -XX:CMSFullGCsBeforeCompaction
## 3.5.7 G1 컬렉터(가비지 우선 컬렉터)
CMS의 명백한 단점은 이후 G1과 같은 컬렉터들에게 자리를 내주는 계기가 되었다.
-> JDK14
G1 컬렉터의 핵심 아이디어는 부분 회수, 리전이라는 메모리 레이아웃 그리고 정지 시간 예측 모델이다.

![[JVM 3장 - G1 컬렉터 메모리 영역.png]]
### 정지 시간 예측 모델
정지 시간 예측 모델은 목표 시간을 M밀리초로 설정하면 GC가 쓰는 시간이 M밀리초가 넘지 않도록 통제하는 것이다.
이를 구현하는데 핵심은 앞서 말한 리전이란 메모리 레이아웃이다.

기존의 GC의 회수 범위는 신세대, 구세대 또는 힙 전체였다. 하지만 G1은 힙 메모리의 어느 곳이든 회수 대상에 포함할 수 있고, 이를 회수 집합(Collection set - CSet)이라고 한다.
이러한 메모리 레이아웃 변경은 **'어느 세대에 속하냐'가 아닌 '어느 영역에 쓰레기가 가장 많으냐'** 라는 발상의 전환으로 **회수 시 이득이 가장 큰 영역을 고를 수 있게** 만들었다.
**즉, 영역 기반 힙 메모리 레이아웃은 정지 시간 예측 모델이라는 목표의 키다.**

### 리전
G1은 세대 단위 컬렉션 이론에 기초하지만 기존의 크기와 수가 고정된 세대 단위 구분에서 벗어나 연속된 자바 힙을 동일 크기의 여러 독립 리전으로 나눈다. 이러한 리전은 G1에서 회수 최소 단위로 사용된다.
각 리전은 필요에 따라 신세대의 에덴이나 생존자 공간이 될 수도, 구세대용 공간으로 사용될 수도 있다. 이를 통해 G1은 회수 효율을 극대화 한다.

한편 G1은 큰 객체라면 '거대 리전'이라는 특별한 유형도 활용한다. **리전 용량의 절반보다 큰 객체를 '큰 객체'로 취급**한다.
만약 리전 하나의 크기를 넘어설 정도의 큰 객체라면 N개의 연속된 리전에 저장된다. G1은 거대 리전을 주로 구세대로 취급한다.

### G1의 처리 방식
G1은 각 리전의 쓰레기 누적 값을 추적한다. 여기서 값이란 **가비지 컬렉션으로 회수할 수 있는 공간의 크기와 회수에 드는 시간의 경험값**이다.
이를 우선순위 목록을 관리하며 사용자가 설정한 일시 정지 시간이 허용하는 한도 내에서 회수 효과가 큰 리전부터 회수한다.

### 리전의 구현 문제
리전의 아이디어 자체는 심플하고 어려울 점이 없다. 하지만 실제 구현을 하게 되면 마주칠 큰 문제들이 존재한다.

첫째,  **자바 힙을 독립된 리전으로 나눈다면 객체들의 리전 간 참조 문제를 해결해야 한다.**
신세대 - 구세대의 경우와 마찬가지로 기억 집합을 통해 해결할 수 있다. 하지만 이를 G1에서 응용하는 것은 훨씬 복잡하다. 모든 리전이 각자의 기억 집합을 관리해야 하기 때문이다.
G1의 기억 집합은 기본적으로 해시 테이블 구조다. **키는 다른 리전으로부터의 시작 주
이고, 값엔 카드 테이블의 인덱스 번호가 원소 집합**으로 이뤄져 있다. 이처럼 '내가 가리키는 대상'과 '나를 가리키는 대상'을 모두 기록하는 양방향 카드 테이블 구조가 되다 보니 기본 카드 테이블보다 구현이 훨씬 복잡하다.

**기억 집합 해시 테이블 예시**
리전 A와 C가 리전 B를 참조한다고 가정해보자.

Key (참조하는 리전 주소) | Value (카드 테이블 인덱스)
Old 리전 A의 시작 주소 | [5, 12, 25] (Young 리전 B의 카드 인덱스)
Old 리전 C의 시작 주소 | [3, 8] (Young 리전 B의 카드 인덱스)

>[!NOTE]
>'내가 가리키는 대상' vs '나를 가리키는 대상'
>기존의 카드 테이블에선 '나'라는 주체는 구세대이다. G1의 카드 테이블에선 '리전'이 주체이므로 자신이 가리키기도, 다른 리전이 자신을 가리키기도 한다.

둘째, **동시 표시 단계 동안 GC 스레드와 사용자 스레드가 서로 간섭하지 않도록 보장**해야 한다.
즉, 사용자 스레드가 객체 참조 관계를 수정해도 원래의 객체 그래프 구조를 파괴하지 않도록 보장해야 한다. 이를 위해 G1에선 '시작 단계 스냅숏' 알고리즘을 선택했다.
G1은 각 리전을 위해 **TAMS라는 두 개의 포인터를 설계**했다. 리전의 공간 일부가 동시 회수 프로세스 동안 새로운 객체를 할당하기 위한 공간으로 나뉘고, **동시 회수 동안 새로 생성되는 객체의 주소는 반드시 이 두 포인터보다 높은 주소 영역에 할당**되어야 한다. G1은 기본적으로 이 주소보다 높이 있는 객체는 암묵적으로 표시되었다고 판단한다. 즉, 회수 대상에서 제외 된다.
만약 **메모리 회수 속도가 메모리 할당 속도를 따라가지 못한다면 G1 역시 모든 사용자 스레드를 멈추고 전체 GC를 수행해야 한다.**

>[!NOTE]
>**TAMS란?**
>GC 스레드와 사용자 스레드 간의 경계를 정의하는 역할
>GC가 동작하는 동안 새로 생성된 객체는 TAMS 포인터보다 높은 주소 영역에만 할당됨

셋째, **신뢰할 수 있는 정지 시간 예측 모델을 구현**해야 한다.
G1의 정지 시간 예측 모델의 이론적 기초는 감소 평균이다. **G1은 리전별 회수 시간, 기억 집합에서 더럽혀진 카드 개수 등 측정할 수 있는 각 단계의 소요 시간을 기록**한다. 그리고 수집한 정보로부터 평균, 표준 편차, 신뢰도 같은 통계를 분석한다.
감소 평균을 기초로 하기 때문에 새로운 데이터에 더 민감하고, 최근의 평균적인 상태를 더 정확하게 알려준다. **즉, 리전의 통계가 최근일수록 회수해서 얻는 가치를 더 높게 쳐 준다.**

이러한 내용에 기반해 G1의 동작은 다음 네 단계로 구분할 수 있다.(사용자 스레드가 실행되는 동안 수행하는 작업 제외)

![[JVM 3장 - G1 컬렉터 동작 방식.png]]
- **최초 표시**(사용자 스레드 정지, 빠름)
  - GC 루트가 직접 참조하는 객체들을 표시하고, TAMS 포인터의 값을 수정
  - 시작 단계 스냅숏을 생성
- **동시 표시**(사용자 스레드와 같이 실행, 느림)
  - 전체 객체 그래프를 재귀적으로 탐색하며 회수 대상을 조회
  - 탐색 종료 후 시작 단계 스냅숏과 비교하여 참조가 변경된 객체를 재스캔
- **재표시**(사용자 스레드 정지, 빠름)
  - 변경된 소수의 객체만 처리하므로 빠름
- **복사 및 청소**(사용자 스레드 정지, 보통)
  - 통계 데이터 기반의 우선 순위 목록에서 회수 대상 리전을 찾음
  - 이 때, 사용자가 설정한 일시 정지 시간에 부합하도록 탐색
  - 회수 대상이 된 리전에서 살아남은 객체들은 빈 리전에 이주하고, 기존 리전은 비움
  - 객체 이동이 일어나므로 사용자 스레드가 정지되어야 함
  - 다수의 GC 스레드가 병렬로 실행

G1의 최대 장점은 일시 정지 시간의 기댓값을 설정할 수 있다는 점이다. 이를 통해 균형점을 찾을 수 있다. 하지만 반드시 현실적인 기댓값일 때만 가능하다.
### 일시 정지 시간을 너무 적게 설정한다면?
목표한 시간이 너무 짧아 힙 영역의 작은 일부만 회수하고 회수 작업이 종료될 것이다. 때문에 회수 속도가 할당 속도를 따라 잡지 못해 쓰레기가 점점 쌓여갈 것이다.

>[!NOTE]
>**G1 vs CMS**
> 작가 경험상 메모리를 적게 쓰는 애플리케이션에선 CMS가 우수하고, 반대는 G1이 우수하다. 자세한 내용은 143p ~ 144p를 확인

## 3.5.8
다양한 GC에 대해 알아 보았지만 현재 사용 중인 GC는 일부분이다.
- 시리얼
- 패러렐
- G1
- ZGC
- 셰넌도어
# 3.6 저지연 가비지 컬렉터
GC의 성능을 측정하는 가장 중요한 지표 세 가지
- **처리량**
- **지연 시간**
- **메모리 사용량**
  이 세 가지는 불가능의 삼각 정리를 만들며 보통 세 가지 중 최대 두 가지만 달성할 수 있다.
  이 중 가장 **지연 시간의 중요성은 더욱 커지고 있다.**
  -> Scale up, out을 한다고 해도 지연 시간을 해결할 수 없다. 오히려 **메모리가 늘어날 경우 지연 시간에는 악영향**을 끼치게 된다.

![[JVM 3장 - GC 동시성 비교.png]]
CMS, G1은 각각 증분 업데이트, 시작 단계 스냅숏을 적용해 표시 단계를 동시 수행할 수 있게 됐다. 이를 통해 **표시할 객체가 많아져도 일시 정지 시간은 늘지 않았지만 표시 단계 이후의 처리는 제대로 해결하지 못했다**.

셰넌도어와 ZGC의 일시 정지 시간은 거의 고정적이다. 즉, 힙 크기와 객체 수에 영향을 거의 받지 않는다. 이러한 컬레터들을 '저지연 컬렉터'라고 한다.

## 3.6.1 셰넌도어
셰넌도어는 OpenJDK에만 존재하는 컬렉터이며, 레드햇이 독립적으로 시작한 프로젝트다.
코드 측면에선 오라클 정통의 ZGC보다 G1을 더 잘 계승했다는 평을 받고 있다.

### G1과의 비교
G1과는 최소 세 가지 부분에서 차이점이 존재한다.
- **동시 모으기 지원**
- **21버전 전까진 세대 단위 컬렉션을 사용하지 않음**
- **기억 집합 대신 연결 행렬로 리전 간 참조 관계 기록**
  - 연결 행렬은 2차원 표로 이해하면 된다.
  - 회수 때 다시 표를 참고해 리전 간 참조를 포함하는 리전들을 알아낸다.
### 동작 방식
![[JVM 3장 - 셰넌도어 동작 방식.png]]
셰넌도어의 동작 방식은 크게 9가지로 구분할 수 있다.
- **최초 표시**(일시 정지 시간 매우 짧음)
  - GC 루트에서 직접 참조하는 객체들에 표시
- **동시 표시**(동시 수행)
  - 객체 그래프를 탐색하며 도달 가능한 모든 객체 표시
  - 사용자 스레드와 동시 수행되며, 수행 시간은 살아 있는 객체 수와 그래프 복잡도에 좌우됨
- **최종 표시**(일시 정지 시간 짦읍)
  - 보류 중인 모든 표시를 완료하고 GC 루트 집합을 다시 스캔
  - **회수 가치가 가장 큰 리전들을 추려 '회수 집합' 생성**
- **동시 청소**
  - 살아 있는 객체가 하나도 없는 리전을 청소
- **동시 이주**
  - 회수 집합 내의 생존 객체를 다른 빈 리전으로 복사
  - 객체 이동은 단번에 가능하지만, 이동 직후 해당 객체를 가리키는 참조 값의 갱신을 동시에 수행하는 것이 복잡함
  - 이를 해결하기 위해 포워딩 포인터, 읽기 장벽을 활용
  - 실행 시간은 회수 집합의 크기에 달림
- **최초 참조 갱신**
  - 스레드들이 집결지를 설정해 동시 이주 단계의 모든 GC 스레드와 사용자 스레드가 이주를 끝마쳤음을 보장
- **동시 참조 갱신**
  - 참조 갱신을 실제로 수행하며, 사용자 스레드와 동시 수행
  - 수행 시간은 메모리에 존재하는 참조의 수에 좌우됨
  - 객체 그래프 탐색 없이 물리 메모리 주소를 순서대로 참조 타입을 선형 검색하며 주솟값 갱신
- **최종 참조 갱신**
  - 힙의 참조 갱신을 마친 후, GC 루트 집합의 참조도 갱신
- **동시 청소**
  - 이주와 참조 갱신이 끝난 뒤 회수 집합의 모든 리전에는 생존 객체가 남지 않음
  - 동시 청소를 다시 수행하여 새로운 객체를 할당할 공간 확보
### 포워딩 포인터
기존엔 이동될 객체의 원래 메모리에 메모리 보호 트랩을 설정해 포워딩 포인터와 비슷하게 동시 이주를 구현했다. 하지만 이 방식은 OS의 지원 없이는 유저 모드와 커널 모드를 수시로 전환해야 해서 비용이 큰 해법이었다.

**포워딩 포인터는 원래의 객체 레이아웃 구조 상단에 참조 필드를 추가하는 해법**이다. 해당 방식은 우회하여 객체에 접근하기 때문에 객체마다 오버헤드가 더해지게 된다. 하지만 해당 방식의 이점은 포인터 하나의 값만 수정하면 된다는 것이다. **즉, 옛 객체의 포워딩 포인터가 새로운 객체를 가리키도록 수정하기만 하면 된다.**

포워딩 포인터 방식을 사용할 때 주의할 점은 크게 두 가지다.
첫째, 스레드 간의 경쟁이다. 데이터를 읽는 것은 상관 없지만 쓰는 것은 **반드시 새로 복사된 객체에만 써야 한다.** 예를 들어 다음과 같은 상황이 있다.
- GC 스레드가 객체의 복사본을 만든다.
- 사용자 스레드가 객체의 필드를 덮어쓴다.
- GC 스레드가 옛 객체의 포워딩 포인터 값을 복사본의 주소로 갱신
  이 경우 **실제로 데이터가 저장되는 곳은 새로운 객체가 아닌 옛 객체**가 된다.
  이를 해결하기 위해선 GC 스레드와 사용자 스레드 중 하나만 포워딩 포인터에 접근해야 한다. 셰넌도어에선 CAS 기법을 써서 해결한다.
  둘째, 실행 빈도다. '객체로의 접근'이 의미하는 바는 그 범위가 매우 넓다. 코드 전역에서 광범위하게 이뤄지기에 이 작업들을 모두 보장하기 위해선 쓰기 장벽과 읽기 작업을 동시에 설정해야 한다. 또한 쓰기 장벽보다 읽기 장벽을 거치는 횟수가 훨씬 많아 일반적으로 읽기 장벽의 비용이 더 크다. 때문에 **실행 빈도가 높을수록 오버헤드가 커질 수 밖에 없다**.

### 로드 참조 장벽 도입
로드 참조 장벽이란 객체 참조 타입의 데이터를 읽고 쓸 때만 끼어드는 메모리 장벽 모델이다. 즉, 원시 데이터 타입 같은 경우 필드를 읽거나 쓸 때 메모리 장벽이 끼어들지 않는다.
로드 참조 장벽은 JDK13에 등장했으며, 읽기 장벽의 오버헤드로 인한 성능 저하를 개선하기 위한 셰년도어의 해결책이다.
이를 토대로 JDK14에선 자가 수리 장벽을 도입한다.

### 포워딩 포인터를 객체 헤더에 통합
이전에 별도로 포워딩 포인터를 뒀을 땐 다른 GC에 비해 메모리를 5~10%정도 더 사용했다.
**객체 헤더의 마크 워드를 포워딩 포인터로 활용하는 방법**으로 이를 해결하며 구체적인 이점은 다음과 같다.
- 같은 공간에 더 많은 객체를 할당하여 GC 작업 횟수가 줄어듦
- CPU 캐시에 더 많은 객체를 담아 캐시 히트율이 높아짐
- 다른 GC와 객체 할당 코드를 공유할 수 있어 구현 로직이 단순해짐

### 스택 워터마크를 활용한 스레드 스택 동시 처리
가비지 컬렉션이 시작되면 모든 스레드의 스택을 스캔하여 참조들을 표시 큐에 담는다. 이 과정에서 사용자 스레드가 스택을 변경하지 못하도록 스레드를 안전 지점에 멈춰 세운 후 진행한다. 이후 사용자 스레드를 깨운 후, 도달 가능한 객체를 탐색한다. 생존할 객체들을 빈 리전으로 이동 시킨 후엔 스택 안의 참조들이 새 객체를 가리키도록 참조를 갱신해야 하고,  이 때도 일시 정지가 필요하다. 스택 스캔 처리에는 수십밀리초의 시간이 소요될 수도 있다.

이를 해결하기 위해 셰넌도어는 스택 워터마크를 사용한다. 스택 워터마크의 핵심 아이디어는 다음과 같다.
- 스택 중 변화가 생기는 부분은 최상위 스택 프레임뿐이다.(현재 실행 중인 메서드)
- 나머지 스택 프레임은 GC가 마음껏 스캔해도 문제가 발생하지 않는다.
- **사용자 스레드가 메서드 반환, 예외 등으로 스택 프레임을 파괴할 때만 조율한다.**

스택 워터마크의 작동 방식
- 최초 표시 때, 모든 스레드의 최상위 프레임 스택 워터마크 설정
- 안전 지점을 벗어난 사용자 스레드가 최상위 프레임을 사용
  - 스택 워터마크가 작동하여 GC가 최상위 프레임을 처리
- 사용자 스레드가 최상위 프레임을 스캔하고 워터마크를 한 칸 낮춤
  - GC 스레드는 스택을 밑에서부터 워터마크까지 스캔
- 사용자 스레드가 최상위 스택 프레임을 파괴하는 경우
  - 워터 마크를 한 칸 낮춤
  - GC 스레드가 워터마크 위로는 스캔하지 못하게 막음
  - 워터마크를 낮춘 결과로 워터마크 위로 떠오른 스택 프레임을 스캔

## 3.6.2 ZGC
ZGC는 다음과 정의할 수 있다.
>ZGC는 세대 구분 없이 리전 기반 메모리 레이아웃을 사용한다. 낮은 지연 시간을 최우선 목표로 하며, 동시 마크-컴팩트 알고리즘을 구현하기 위해 읽기 장벽, 컬러 포인터, 메모리 다중 매핑 기술을 이용하는 가비지 컬렉터다.

### 리전 기반 메모리 레이아웃
G1, 셰넌도어와 달리 ZGC의 리전은 동적으로 생성/파괴되며 크기 또한 동적으로 달라진다.
ZGC의 리전 크기는 다음과 같이 구분할 수 있다.
- **소리전(2MB)**
  - 256KB 미만의 작은 객체를 할당하기 위한 공간
- **중리전(32MB)**
  - 256KB ~ 4MB미만의 객체를 할당하기 위한 공간
- **대리전(최소 4MB, 단 2MB의 배수로 커짐)**
  - 4MB 이상의 큰 객체를 할당하기 위한 공간
  - 큰 객체 하나만을 담으며, 재할당이 이뤄지지 않음(비용이 크기 때문에)
  - 이러한 특성 때문에 실제 크기는 중리전보다 작을수도 있음

### 병렬 모으기와 컬러 포인터
ZGC를 상징하는 설계는 컬러 포인터다. 이러한 설계가 나온 데는 다음과 같은 이유가 존재한다.
- 객체가 이동할 수 있는 환경에서 **객체로의 접근이 반드시 성공함을 보장하기 힘듦**
- **필요한 정보를 객체와 관련 없는 포인터나 장소로부터 얻어야 하는 경우**가 존재
  기존의 포인터는 이러한 니즈를 충족하기 쉽지 않았다. 단지 참조를 하냐 안하냐만 알 수 있기 때문이다.
  컬러 포인터는 이러한 니즈를 충족하는 기술이다. 즉, 포인터 자체에 소량의 추가 정보를 직접 저장하는 기술이다.

#### 컬러 포인터는 어떻게 구현할까?
![[JVM 3장 - 컬러 포인터.png]]
컬러 포인터 기술은 64비트 하드웨어서만 동작한다. 메모리의 주소 공간을 44비트까지로 제한하고, 다음 상위 4비트를 네 가지 플래그 정보를 저장하는데 이용한다. 4비트를 플래그에 할애함으로써 메모리 용량을 제한하고, 32비트 플랫폼에선 동작하지 않으며, 압축 포인터 같은 여러 기술을 지원할 수 없게 된다.
이러한 단점에도 불구하고 컬러 포인터를 쓰는 장점은 다음과 같다.
- **한 리전 안의 생존 객체들이 이동하면 그 즉시 해당 리전을 재활용할 수 있다.**
  - 전체 힙에서 **해당 리전으로의 참조들을 전부 수정할 때까지 기다릴 필요가 없다**는 뜻이다. (**자가 치유** 덕분에)
  - 이에 반해 셰넌도어는 참조 갱신 단계가 끝나기 전에는 회수 중인 리전을 재활용하지 못한다.
- **가비지 컬렉션 과정에서 메모리 장벽의 수를 크게 줄일 수 있다.**
  - 쓰기 장벽을 설정하는 이유는 주로 객체 참조를 변경하기 위함이다.
  - 이 정보를 **포인터 자체에 기록해두면 일부 기록 작업은 필요 없어**진다.
- **컬러 포인터를 객체 표시 및 재배치와 관련해 더 많은 정보를 담을 수 있는 확장 가능한 저장 구조로 쓸 수 있다.**
  - 미래에 또 다른 성능 향상을 이끌 잠재력이 존재한다.

>[!NOTE]
>사용안함(16비트)'는 하드웨어 아키텍처, OS의 제약 조건 때문에 사용할 수 없는 공간이다.
>64비트 시스템은 이론상 16EB(2의 64제곱)크기의 메모리를 이용할 수 잇지만 현실적인 요구 사항, 성능, 비용을 고려하면 모두 이용할 필요는 없게 된다. 그래서 x84-64 아키텍처는 최대 52비트의 주소 버스와 48비트의 가상 주소 공간만 사용한다. 따라서 현재 64비트 하드웨어가 지원할 수 있는 최대 메모리는 256TB다. 더불어, 64비트 리눅스의 프로세스 가상 주소 공간은 47비트(128TB)이며, 물리 주소 공간은 46비트(64TB)다

#### 컬러 포인터는 문제가 없을까?
컬러 포인터는 굉장히 유용한 설계지만 JVM이 포인터를 임의로 재정의 한다는 태생적인 한계가 존재한다. 즉, **OS 레벨에선 JVM에서 정의한 의미대로 동작함을 기대할 수 없다는 것**이다. OS 입장에선 그저 전체를 메모리 주소라고 생각할 뿐이다.

가상 주소 마스크를 하드웨어 수준에서 지원하는 스팍용 솔라리스 시스템과 달리 x86-64 아키텍처에선 이를 지원하는 기술이 없다. 그래서 ZGC 설계자들이 **선택한 방법은 가상 메모리 매핑 기술**이다.

#### 가상 메모리 매핑
![[JVM 3장 - 가상 메모리 매핑.png]]
말 그대로 실제 물리 메모리와 가상 메모리를 매핑하는 기술이다. 이 관계는 **일대일, 일대다, 다대일, 다대다 어떤 방식으로도 설계 가능하며, 하드웨어 및 OS, 소프트웨어 프로세스 수준에서도 구현**할 수 있다.
x86-64용 리눅스 플랫폼에서 ZGC는 **여러 가상 메모리 주소를 하나의 똑같은 물리 메모리 주소로 매핑하는 방식**을 사용한다. 컬러 포인터의 플래그 비트들을 주소의 세그멘테이션 기호로 사용한다면 다중 매핑 변환을 거친 다음에는 컬러 포인터 역시 일반적인 주소 지정에 사용할 수 있다.

### ZGC의 동작 방식
![[JVM 3장 - ZGC 동작 프로세스.png]]
ZGC의 동작은 크게 네 단계로 나눌 수 있다. 모든 단계는 동시 실행되지만, 사이사이에 사용자 스레드를 일시 정지시키는 작은 단계가 존재한다.
- **동시 표시**
  - G1이나 셰넌도어와 유사하게 동작하지만 **ZGC의 표시는 객체가 아닌 포인터에서 이뤄진다는 차이점이 존재**한다.
  - 컬러 포인터의 Marked0, 1 플래그가 이 단계에서 갱신된다.
- **동시 재배치 준비**
  - 청소해야 할 리전들을 선정해 재배치 집합을 생성
  - 모든 리전을 스캔해야 하기에 재배치 집합에서는 리전 안의 생존 객체들을 다른 리전으로 복사한 후 리전 자체를 회수할지 여부만 결정
  - 재배치 집합에 포함되지 않은 리전들도 회수 대상이 될 수 있음
- **동시 재배치**
  - ZGC의 핵심 단계이며, **재배치 집합 안의 생존 객체들을 새로운 리전으로 복사**
  - 재배치 집합에 속한 각 리전의 포워드 테이블에 신/구 객체의 이주 관계를 기록
  - 컬러 포인터 덕분에 ZGC는 객체가 재배치 집합에 속하는지 참조만 보고 판단
  - 객체의 참조 갱신은 포인터의 자가 치유로 수행
  - 컬러 포인터의 자가 치유 덕분에 재배치 집합에 속한 생존 객체들의 복사가 모두 끝나는 즉시 해당 리전을 재활용할 수 있음(단, 포워드 테이블은 아직 회수되면 안됨)
- **동시 재매핑**
  - 재매핑이란 힙 전체에서 재배치 집합에 있는 옛 객체들을 향하는 참조 전부를 갱신하는 작업이다. 목적은 셰넌도어의 '동시 참조 갱신'과 같지만 ZGC에선 급히 처리하지 않아도 괜찮음(자가 치유 덕분)
  - 이 점을 활용해 ZGC는 재매핑 단계를 다음 가비지 컬렉션 주기가 시작되는 동시 표시 단계와 통합하여 두 번의 객체  그래프 탐색을 1번으로 줄임

>[!NOTE]
>**포인터의 자가 치유**
>사용자 스레드가 재배치 집합에 포함된 객체에 동시에 접근하려 들면 미리 설정해둔 메모리 장벽이 끼어 들어, 즉시 해당 리전의 포워드 테이블에 기록된 정보를 보고 새로운 객체로 포워드 시킨다. 그와 동시에 참조의 값도 새로운 객체를 직접 가리키도록 갱신한다.
>이 과정을 포인터의 자가 치유라고 한다.
>**자가 치유의 장점은 옛 객체에 처음 접근할 때만 포워드가 일어난다는 것이다.**

### 다른 컬렉터와의 비교
- **G1**
  - 세대 간 참조, 리전들의 점진적 회수 처리를 위해 기억 집합을 활용
  - 기억 집합 관리엔 쓰기 장벽을 활용
  - 메모리 사용량이 큰 기억 집합과 쓰기 장벽의 부하라는 단점이 존재
- **ZGC**
  - 기억 집합이 없어 메모리 사용량이 적고, 쓰기 장벽을 쓰지 않아 부하가 줄어듦
  - 하지만 객체 할당 속도를 제한하는 단점이 존재
  - ZGC는 세대 구분을 하지 않기 때문에 매 가비지 컬렉션마다 모든 리전을 탐색해야 함
  - 그렇기에 할당 속도가 회수 속도보다 빠르면 부유 쓰레기가 생겨나고 이로 인해 힙이 부족해질 수 있음
  - 근본적인 해결책은 세대 단위 컬렉션 도입임
  - NUMA 메모리를 고려한 메모리 할당이 큰 장점 중 하나다.
    - NUMA 아키텍처가 적용된 환경에서라면, ZGC는 객체 생성을 요청한 스레드가 수행 중인 프로세서의 지역 메모리에 우선적으로 객체를 할당해 메모리 접근 효율을 높임

## 3.6.3 세대 구분 ZGC
ZGC를 확장하여 신세대와 구세대를 구분하며 JDK 21에 추가되었다. 초기에 이를 구현하지 않은 이유는 구현 복잡도에 따른 시간 비용이 컸기 때문이다.
JDK 21 기준으로 세대 구분 ZGC가 ZGC를 대체한 것은 아니다. -XX:+UseZGC 매개 변수를 지정하면 일반 ZGC를 사용할 수 있다.  더불어 세대 구분 ZGC를 적용하려면 -XX:+ZGenerational을 추가해야 한다.

세대 구분 ZGC는 컬러 포인터, 읽기 장벽 기술을 그대로 사용한다. 또한 쓰기 장벽도 활용한다. 물론 기존 GC들보다 더 효율적으로 사용한다. 이 외에도 수많은 기법이 적용되어 ZGC를 한층 더 향상시켰다.
### 다중 매핑 메모리 제거
ZGC는 읽기 장벽 부하를 줄이기 위해 다중 매핑 메모리 기법을 사용한다. 세대 구분 ZGC는 읽기 장벽과 쓰기 장벽의 코드를 명확히 구분한다. GC 관점에선 컬러 포인터에 다중 매핑 관련 메타데이터 비트들을 다른 용도로 활용할 수 있게 됐다.

### 다양한 장벽 최적화
처리량을 극대화하려면 장벽들을 정밀하게 최적화 해야 하는데, 기억 집합 장벽, 시작 단계 스냅숏 표시 장벽 등 수 많은 기법을 고안해 적용했다.

### 이중 버퍼를 이용한 기억 집합 관리
앞서 기억 집합을 구현 하는 대표적인 구현체가 카드 테이블이라고 배웠다. 카드 테이블은 정밀도가 가장 낮은 방식이었다. 그렇기 때문에 구세대에서 신세대를 가리키는 포인터를 찾으려면 GC는 카드 범위에 존재하는 모든 객체 필드를 확인해야 했다.
이를 해결하기 위해 세대 구분 ZGC에선 비트맵을 활용해 객체 필드의 위치를 정확하게 기록한다. 비트맵의 비트 하나가 객체 필드 주소 하나를 표현하며, 구세대 리전 각각이 한 쌍의 기억 집합 비트맵을 가지고 있다.

### 밀집도 기반 리전 처리
최근에 할당된 리전이라면 더 많은 객체가 살아 있을 가능성이 크다. 세대 구분 ZGC는 **회수할 리전을 결정하기 위해 밀집도를 분석**한다. 회수 대상이 아닌 리전들은 그대로 나이를 먹어 생존자 리전이 되거나 구세대 리전으로 승격된다. 생존자 리전은 다음번 신세대 GC 때는 밀집도가 더 높아져 회수 대상이 될 가능성이 자연스럽게 높아진다.

### 거대 객체 처리
세대 구분 ZGC에서는 거대한 객체도 신세대에 바로 할당한다.  하지만 살아남은 거대 객체를 구세대로 재배치 할 필요는 없다. 재배치 없이 리전 자체를 노화시키기 때문이다.

# 3.7 적합한 가비지 컬렉터 선택하기

ZGC - https://d2.naver.com/helloworld/0128759