## 5.2 사례 분석

### 5.2.1 대용량 메모리 기기 대상 배포 전략

- 배경
    - 웹 사이트 하드웨어 교체
    - 하루 PV 15만
    - 16GB 메모리
    - JDK 5
    - -Xmx, -Xms 매개변수를 지정하여 자바 힙 크기를 12GB로 고정
        - (기존 1.5GB)
- 문제
    - 서버 실행 효율이 나쁘고, 웹 사이트가 장시간 응답하지 않는 경우가 잦음
    - 기존에는 조금 느리기는 해도, 10초 이상 답이 없는 경우는 없었음
- 원인
    - GC
        - 패러렐 컬렉터 (패러렐 스캐빈지 + 패러렐 올드)
            - 일시 정지 시간보다는 처리량에 중점을 둔 컬렉터임
            - 전체 GC를 위해 최장 14초 일시 정지
        - 웹 페이지 파일을 디스크에서 메모리로 로드
            - 웹 페이지를 직렬화하는 과정에서 거대 객체가 다수 쌓임
            - 거대 객체는 곧바로 구세대에 만들어짐
- 해결책
    - 힙 크기를 1.5 ~ 2GB 정도로 줄이기
    - 저지연 GC(셰넌도어, ZGC)를 사용
    - 가상 머신 여러 개를 띄워 논리적인 클러스터를 구성
        - 장점
            - 하드웨어 자원을 효율적으로 사용
            - 힙 크기를 줄여서 GC 시간을 단축
        - 단점
            - 전역 자원 경합 문제 (e.g., 디스크 read 시 I/O 예외)
            - 커넥션 풀을 효율적으로 쓰기 어려움
                - 특정 노드의 풀에 작업이 쏠릴 수 있음
                - 중앙화된 JNDI로 해결은 가능하지만, 복잡하고 추가적인 성능 비용 발생
            - 32bit JVM에서 노드별 메모리가 2GB로 제한 (힙은 1.5GB)
            - 로컬 캐시를 많이 사용하는 경우, 노드별로 중복되어 메모리 낭비
- 해결
    - 가상 머신 5개를 띄우고, 프로세스당 메모리 2GB할당
    - 앞단에 아파치를 띄워서 로드 밸런싱
    - GC는 CMS로 변경
        - 고객들은 응답 속도를 중요하게 생각하므로, 페이지 기반 웹 사이트에서는 디스크와 메모리 접근 시간이 중요하고, 프로세서 자원에는 상대적으로 둔감
        - 따라서 처리량보다는 응답 시간을 우선시하는 CMS로 변경
    - → 장시간 일시 정지 문제가 사라졌고, 응답 속도도 빨라짐

### 5.2.2 클러스터 간 동기화로 인한 메모리 오버플로

- 배경
    - 컴퓨터 2대 - 8GB 메모리
    - 각각 WebLogic 3개씩 구동하여, 총 6 노드의 클러스터 구성
    - 선호도 클러스터이므로 세션 동기화는 불필요
- 문제
    - 일부 데이터 공유 필요
        - 처음에는 DB를 사용했지만 읽기/쓰기가 잦고 경합이 많아서 성능이 좋지 않았음
        - JBossCache(→ 인메모리 분산 캐시)를 사용해 글로벌 캐시를 구축해서 원활히 운영했으나, 가끔 메모리 오버플로우가 발생
- 원인
    - JBossCache의 클러스터 간 통신 방식
    - 데이터 전송 실패로 재전송해야 하는 경우를 대비해, 다른 노드들이 데이터를 잘 수신했는지 확인하기 전까지는, 데이터를 메모리에 보관함

### 5.2.3 힙 메모리 부족으로 인한 오버플로 오류

- 배경
    - 온라인 시험 시스템
    - 서버 푸시 기술(CometD 1.1.1)을 사용해 클라이언트가 서버로부터 시험 데이터를 실시간으로 받아옴
        - 메모리 4GB, 32bit 윈도우
- 문제
    - 테스트 중 서버에서 메모리 오버플로가 발생
    - 힙 메모리를 최대로 늘렸으나(1.6GB) 여전히 문제
    - GC는 자주 일어나지 않는데도 불구하고 메모리 오버플로가 발생하고 있었음
- 원인
    - 32bit 윈도우에서 프로세스가 사용할 수 있는 메모리는 2GB이고, 그 중 1.6GB를 힙에 할당했음
        - 다이렉트 메모리는 0.4GB
    - 다이렉트 메모리도 GC의 대상인데, 힙과 달리 메모리가 부족하더라도 GC에 메모리 부족을 알릴 방법이 없음
    - 따라서 힙의 구세대가 꽉 차서 전체 GC가 수행되어야만 다이렉트 메모리에 GC가 수행될 수 있음
    - CometD 1.1.1은 다이렉트 메모리를 이용하는 NIO 연산을 매우 많이 수행함
    - 물리 메모리 용량이 적은 시스템이나 32bit 애플리케이션은, 힙과 메서드 영역 외의 영역들도 상당한 비중을 차지하고, 메모리 총합이 프로세스 허용 한계를 넘는 경우가 많음

### 5.2.4 시스템을 느려지게 하는 외부 명령어

- 프로세서 이용률은 매우 높았으나, 프로세서 자원의 대부분을 소비하는 주체는 이 시스템이 아니었음
- 시스템 정보를 얻기 위해, 셸 스크립트를 실행하고 있었음
    - 프로세스를 복사하고, 그 프로세스에서 외부 명령을 실행하고, 프로세스를 종료하는 과정이 반복적으로 수행됨
- 해결
    - 셸 스크립트 실행 코드를 지우고, 필요한 정보를 자바 API로 가져오도록 수정

### 5.2.5 서버 가상 머신 프로세스 비정상 종료

- 배경 (5.2.2절과 동일)
    - 컴퓨터 2대 - 8GB 메모리
    - 각각 WebLogic 3개씩 구동하여, 총 6 노드의 클러스터 구성
    - 최근 사무 자동화 포털과 연동함
- 문제
    - 가상 머신 프로세스가 갑자기 자주 죽는 현상
        - 예외 메시지 - 원격지에서 연결을 끊음
    - 경영 정보 시스템의 할 일 항목의 상태가 바뀌면, 사무 자동화 포털이 이 정보를 받아와서 동기화함
        - 이 동기화 요청은 3분이 넘어서 타임아웃이 되고 있음
    - 경영 정보 시스템의 이융자가 매우 많아서, 사무 자동화 시스템의 속도에 영향을 받지 않도록 비동기 호출을 하고 있었음
        - 그러나 사무 자동화 시스템의 응답이 느려서, 대기 중인 스레드와 소켓 연결이 점점 많아지다가, JVM 프로세스가 비정상 종료됨
- 해결
    - 사무 자동화 시스템과의 연동 인터페이스를 수정하고, 비동기 호출 부분을 pub/sub 방식의 메시지 큐로 변경하여 해결

### 5.2.6 부적절한 데이터 구조로 인한 메모리 과소비

- 배경
    - 메모리 설정 -Xms4g, -Xmx8g, -Xmn1g
        - 에덴 영역의 용량은 신세대의 80%인 800MB
    - 파뉴 + CMS GC 조합
    - 평상시에 마이너 GC 시간은 보통 30ms 안쪽이어서 문제 없었음
- 문제
    - 데이터 분석을 위해 10분 단위로 80MB 파일을 메모리로 읽어들이는데, 이 때, 100만개 이상의 HashMap<Long, Long> 객체를 생성
    - 마이너 GC가 100만개가 넘는 객체를 검사하느라 일시 정지가 500ms로 지나치게 늘어남
- 원인
    - 데이터 파일 분석하는 동안 에덴이 빠르게 채워져서 마이너 GC 발생
    - 마이너 GC 후에도 신세대의 객체 대부분은 살아있음
    - 파뉴 컬렉터는 복사 알고리즘을 이용하고, 복사 알고리즘은 대부분의 객체가 죽어야 효율이 좋음
        - 생존한 객체가 많다면 이들을 생존자 공간으로 복사하게 되므로, GC 시간이 급격히 늘어남
- 해결책
    - 생존자 공간을 제거하여, 첫번째 마이너 GC 후 생존한 객체를 곧바로 구세대로 옮기는 방법
        - 다음 메이저 GC에서 죽은 객체를 회수하게끔 하는 방법이지만, 부작용이 큼
    - HashMap<Long, Long>을 수정
        - Long, Long을 키, 밸류로 사용하는 경우는 공간 효율성이 매우 낮음
            - 의미있는 데이터는 long 정수 2개이므로 = 16바이트
            - long 데이터를 감싸는 Long 객체는 마크 워드(8바이트), 클래스 포인터(8바이트), 데이터(8바이트) = 24바이트
            - Map.Entry에 이 Long 객체를 저장하는데, 객체 헤더(16바이트), next 필드(8바이트), 해시 필드(4바이트), 패딩(4바이트) = 32 바이트
            - Map.Entry를 가리키는 참조 8 바이트
            - 의미있는 데이터 / 실제 데이터 = 16 / (24 * 2+ 32 + 8) = 18%
        - → Trove4j, FastUtil 처럼, 원시 타입을 지원하는 컬렉션 라이브러리를 사용
    - G1GC나 ZGC를 사용(?)
        - (만능은 아닐 텐데, 근거가 부족..)

### 5.2.7 윈도우 가상 메모리로 인한 긴 일시 정지

- 배경
    - 심장 박동을 보여주는 GUI 데스크톱 프로그램
    - 서드 파티 서비스로부터 15초마다 데이터를 얻어옴
    - 30초 내로 회신하지 않으면 연결이 끊긴 것으로 간주
- 문제
    - 위양성(false positive → 연결이 끊기지 않았지만 끊겼다고 잘못 판단한) 데이터가 자주 섞여 들어옴
    - 프로그램이 약 1분 간격으로 로그 출력없이 일시 정지 상태가 되기 때문
    - GC가 대체로 100ms 이내로 끝나지만, 간혹 1분 가까이 길게 걸리는 경우가 있었음
        - GC 자체는 오래 걸리지 않았으나, GC 준비 단계가 오래 걸렸음
    - 프로그램 창을 최소화 하면 메모리 사용량이 급격하게 줄어들었으나, 가상 메모리에는 변화가 없음
        - 작업 메모리가 디스크로 스와프 된다고 추측
        - 이 상태에서 GC를 하면 스와프된 데이터를 다시 메모리로 불러오느라, GC 시간이 길어짐
- 해결
    - -Dsun.awt.KeepWorkingSetOnMinimize=true 매개변수를 추가하여 해결

### 5.2.8 안전 지점으로 인한 긴 일시 정지

- 배경
    - 일반적인 컴퓨팅 작업을 처리하는 비교적 큰 HBase 클러스터
    - JDK 8, G1GC 사용
    - 대량의 맵리듀스나 스파크 오프라인 분석을 수행
    - 오프라인 분석에서 지연 시간은 그다지 중요하지 않으므로, -XX:MaxGCPauseMillis 매개변수를 500ms로 넉넉히 설정함
- 문제
    - GC 일시 정지가 3초 이상까지 길어지는 일이 빈번해짐
    - GC가 실제로 객체를 회수하는 시간은 수백ms 정도밖에 소요되지 않았음
- 원인
    - 안전 지점이 너무 많아지는 것을 막고자, 핫스팟은 순환문을 평가하여 최적화함
        - int 혹은 더 작은 타입을 루프 변수로 이용하는 순환문은 반복 횟수가 적다는 가정 하에, 안전 지점으로 설정되지 않음 → 카운티드 루프
        - long처럼 큰 타입을 루프 변수로 사용하는 경우에는 안전 지점으로 설정 → 언카운티드 루프
    - 순환문을 한번 수행하는 시간 자체가 너무 길다면, 카운티드 루프라도 오래걸림
    - HBase의 연결 타임아웃 초기화 기능
        - 맵리듀스와 스파크 태스크의 연결 기능이 다수 있었고, 태스크 각각이 많은 수의 연결을 만들어냄
        - 연결을 초기화하는 순환문의 루프 변수가 int 타입(카운티드 루프)이었기 때문에, 안전 지점이 설정되지 않음
        - GC가 시작되려고 할 때, RocServer의 리스너 스레드가 카운티드 루프에 진입했다면, 이 순환문을 다 끝마치고 안전 지점에 도달할 때까지 기다려야만 함
        - 다른 스레드들도 함께 대기하게 되고, 일시 정지 시간이 길어짐
- 해결
    - 루프 변수 타입을 long으로 변경하여 해결